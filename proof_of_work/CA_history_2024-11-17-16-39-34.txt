2024-11-17-16-39-34 106 1 import matplotlib.cm as cm	import matplotlib.pyplot as plt	from sklearn.decomposition import PCA		def plot_dataset(data: np.ndarray, labels: np.ndarray) -> None:	    if (data.ndim == 1):	        return	    data_2d = PCA(n_components=2).fit_transform(data)	    unique_labels = np.unique(labels)	    cmap = cm.get_cmap('tab10', len(unique_labels))	    for cluster_label in unique_labels:	        cluster_data = data_2d[labels == cluster_label]	        plt.scatter(*cluster_data.T, alpha=0.5, color=cmap(cluster_label), label=f'Cluster {cluster_label}')	    plt.axis('equal')	    plt.xlabel('PCA Component 1')	    plt.ylabel('PCA Component 2')	    plt.legend()	    plt.grid()	    plt.show()	    return		save_history()
2024-11-17-16-39-34 106 2 get_ipython().run_line_magic('matplotlib', 'inline')	import matplotlib.pyplot as plt	from typing import Tuple	import numpy as np	import scipy as sp	from submission_utils import save_history, check_and_prepare_for_submission	# import warnings filter	from warnings import simplefilter	# ignore all future warnings	simplefilter(action='ignore', category=FutureWarning)
2024-11-17-16-39-34 106 3 def create_dataset(num_clusters: int, 	                   num_dimensions: int, 	                   num_points: np.ndarray, 	                   cluster_std_devs: np.ndarray, 	                   center_std_dev: float) -> Tuple[np.ndarray, np.ndarray]:	    data = []	    labels = []	    origin = np.zeros((num_dimensions,))	    cluster_centres = np.random.normal(loc=origin, scale=center_std_dev, size=(num_clusters, num_dimensions))	    for i in range(num_clusters):	        cluster_points = np.random.normal(loc=cluster_centres[i], scale=cluster_std_devs[i], size=(num_points[i], num_dimensions))	        for point in cluster_points:	            data.append(point)	            labels.append(i)	    data = np.array(data)	    labels = np.array(labels)	    return (data, labels)		save_history()
2024-11-17-16-39-34 106 4 # This cell is reserved for the unit tests. Do not consider this cell. 
2024-11-17-16-39-34 106 5 # This cell is reserved for the unit tests. Do not consider this cell. 
2024-11-17-16-39-34 106 6 def pca_with_svd(data: np.ndarray, n_components: int) -> np.ndarray:	    centred_data = data - np.mean(data, axis=0)	    u, s, vh = np.linalg.svd(centred_data)	    transformed_data = centred_data.dot(vh.T[:, :n_components])	    return transformed_data		save_history()
2024-11-17-16-39-34 106 7 # This cell is reserved for the unit tests. Do not consider this cell. 
2024-11-17-16-39-34 106 8 import matplotlib.cm as cm	import matplotlib.pyplot as plt	from sklearn.decomposition import PCA		def plot_dataset(data: np.ndarray, labels: np.ndarray) -> None:	    if (data.ndim == 1):	        return	    data_2d = PCA(n_components=2).fit_transform(data)	    unique_labels = np.unique(labels)	    cmap = cm.get_cmap('tab10', len(unique_labels))	    for cluster_label in unique_labels:	        cluster_data = data_2d[labels == cluster_label]	        plt.scatter(*cluster_data.T, alpha=0.5, color=cmap(cluster_label), label=f'Cluster {cluster_label}')	    plt.axis('equal')	    plt.xlabel('PCA Component 1')	    plt.ylabel('PCA Component 2')	    plt.legend()	    plt.grid()	    plt.show()	    return		save_history()
2024-11-17-16-39-34 106 9 # This cell is reserved for the unit tests. Do not consider this cell. 
2024-11-17-16-39-34 106 10 def impute_missing_values(data: np.ndarray, rank: int) -> np.ndarray:	    no_nan_data = np.nan_to_num(data, nan=0)	    u, s, vh = np.linalg.svd(no_nan_data)	    s = np.diag(s)	    num_cols_u = u.shape[1]	    if num_cols_u > rank:	        u_trunc = u[:, :rank]	    else:	        u_trunc = u	    num_cols_vh = vh.shape[1]	    if num_cols_vh > rank:	        vh_trunc = vh[:rank, :]	    else:	        vh_trunc = vh	    num_sinuglar_values = s.shape[0]	    if num_sinuglar_values > rank:	        s_trunc = s[:rank, :rank]	    else:	        s_trunc = s	    trunc_svd_data = np.dot(np.dot(u_trunc, s_trunc), vh_trunc)	    nan_mask = np.isnan(data)	    nan_indices = np.where(nan_mask)	    imputed_data = data.copy()	    for row_ind, col_ind in zip(nan_indices[0], nan_indices[1]):	        impute_value = trunc_svd_data[row_ind, col_ind]	        imputed_data[row_ind, col_ind] = impute_value	    return imputed_data		save_history()
2024-11-17-16-39-34 106 11 # This cell is reserved for the unit tests. Do not consider this cell. 
2024-11-17-16-39-34 106 12 # Step 1: Create a 5-dimensional dataset with 3 clusters	num_clusters = 3	num_dimensions = 5	num_points = np.array([100, 100, 100])	cluster_std_devs = np.array([1.0, 1.0, 1.0])	center_std_dev = 3.0		data, labels = create_dataset(num_clusters, num_dimensions, num_points, cluster_std_devs, center_std_dev)		# Step 2: Plot the original data (2D projection using PCA)	print("Original Data (2D projection)")	plot_dataset(data, labels)		# Step 3: Introduce 10% missing values	nan_data = data.copy()	num_elements = nan_data.size	num_nan = int(0.1 * num_elements)  # 10% of the data		# Randomly choose 10% of indices to set as NaN	nan_indices = np.random.choice(num_elements, num_nan, replace=False)	nan_data.ravel()[nan_indices] = np.nan		# Step 4: Impute missing values using rank-4 SVD approximation	imputed_data = impute_missing_values(nan_data, rank=4)		# Step 5: Plot the imputed data (2D projection using PCA)	print("Imputed Data (2D projection)")	plot_dataset(imputed_data, labels)
2024-11-17-16-39-34 106 13 from sklearn.neighbors import NearestNeighbors		def construct_knn_graph(data: np.ndarray, k: int) -> np.ndarray:	    knn = NearestNeighbors(n_neighbors=k + 1)	    knn.fit(data)	    distances, indices = knn.kneighbors(data)	    num_samples = data.shape[0]	    knn_graph = np.zeros((num_samples, num_samples))	    for i, (distances_vector, indices_vector) in enumerate(zip(distances, indices)):	        for distance, j in zip(distances_vector, indices_vector):	            knn_graph[i, j] = distance	            knn_graph[j, i] = distance	    return knn_graph		save_history()
2024-11-17-16-39-34 106 14 from scipy.sparse import csr_matrix	from scipy.sparse.csgraph import dijkstra		def compute_geodesic_distances(knn_graph: np.ndarray) -> np.ndarray:	    num_samples = knn_graph.shape[0]	    geodesic_distances = np.zeros((num_samples, num_samples))	    knn_cs_graph = csr_matrix(knn_graph)	    for i in range(num_samples):	        distances_vector = dijkstra(csgraph=knn_cs_graph, directed=False, indices=i)	        geodesic_distances[i] = distances_vector	    return geodesic_distances		save_history()
2024-11-17-16-39-34 106 15 from sklearn.manifold import MDS		def apply_mds(geodesic_distances: np.ndarray, n_components: int) -> np.ndarray:	    embedding = MDS(n_components=n_components, dissimilarity='precomputed')	    geodesic_distances[geodesic_distances == np.inf] = 1e9	    reduced_data = embedding.fit_transform(geodesic_distances)	    return reduced_data		save_history()
2024-11-17-16-39-34 106 16 def isomap(data: np.ndarray, n_components: int, k: int) -> np.ndarray:	    knn_graph = construct_knn_graph(data, k)	    geodesic_distances = compute_geodesic_distances(knn_graph)	    reduced_data = apply_mds(geodesic_distances, n_components)	    return reduced_data		save_history()
2024-11-17-16-39-34 106 17 # This cell is reserved for the unit tests. Do not consider this cell. 
2024-11-17-16-39-34 106 18 # This cell is reserved for the unit tests. Do not consider this cell. 
2024-11-17-16-39-34 106 19 # This cell is reserved for the unit tests. Do not consider this cell. 
2024-11-17-16-39-34 106 20 # This cell is reserved for the unit tests. Do not consider this cell. 
2024-11-17-16-39-34 106 21 def initialize_centroids(data: np.ndarray, k: int) -> np.ndarray:	    centroids = []	    num_samples = data.shape[0]	    for _ in range(k):	        rand_ind = np.random.choice(num_samples)	        rand_data_point = data[rand_ind]	        centroids.append(rand_data_point)	    centroids = np.array(centroids)	    return centroids		save_history()
2024-11-17-16-39-34 106 22 # This cell is reserved for the unit tests. Do not consider this cell. 
2024-11-17-16-39-34 106 23 def assign_clusters(data: np.ndarray, centroids: np.ndarray) -> np.ndarray:	    num_clusters = centroids.shape[0]	    labels = []	    for data_point in data:	        best_centroid_ind = 0	        best_euclidean_distance = 1e9	        for i in range (num_clusters):	            centroid = centroids[i]	            euclidean_distance = sum((centroid_val - data_point_val) ** 2 for centroid_val, data_point_val in zip(centroid, data_point)) ** 0.5	            if (euclidean_distance < best_euclidean_distance):	                best_euclidean_distance = euclidean_distance	                best_centroid_ind = i	        labels.append(best_centroid_ind)	    labels = np.array(labels)	    return labels		save_history()
2024-11-17-16-39-34 106 24 # This cell is reserved for the unit tests. Do not consider this cell. 
2024-11-17-16-39-34 106 25 def update_centroids(data: np.ndarray, labels: np.ndarray, k: int) -> np.ndarray:	    clusters = {}	    for i in range(k):	        clusters[f"{i}"] = []	    for i, data_point in enumerate(data):	        clusters[f"{labels[i]}"].append(data_point)	    new_centroids = []	    for i in range(k):	        cluster = np.array(clusters[f"{i}"])	        new_centroids.append(np.array([np.mean(feature) for feature in cluster.T]))		    new_centroids = np.array(new_centroids)	    return new_centroids		save_history()
2024-11-17-16-39-34 106 26 # This cell is reserved for the unit tests. Do not consider this cell. 
2024-11-17-16-39-34 106 27 def kmeans(data: np.ndarray, k: int, max_iter: int = 100, tol: float = 1e-4) -> Tuple[np.ndarray, np.ndarray]:	    centroids = initialize_centroids(data, k)	    labels = assign_clusters(data, centroids)	    max_movement = 1e9	    while (tol < max_movement and max_iter > 0):	        old_centroids = centroids.copy()	        centroids = update_centroids(data, labels, k)	        movements = []	        for i in range(centroids.shape[0]):	            old_centroid = old_centroids[i]	            centroid = centroids[i]	            movements.append(sum((old_val - val) ** 2 for old_val, val in zip(old_centroid, centroid)) ** 0.5)	        max_movement = max(movements)	        labels = assign_clusters(data, centroids)	        max_iter -= 1	    return (centroids, labels)		save_history()
2024-11-17-16-39-34 106 28 # This cell is reserved for the unit tests. Do not consider this cell. 
2024-11-17-16-39-34 106 29 def within_cluster_distances(data: np.ndarray, labels: np.ndarray) -> np.ndarray:	    num_samples = data.shape[0]	    within_distances = np.zeros((num_samples,))	    for result_ind, (data_point, cluster_ind) in enumerate(zip(data, labels)):	        cluster_points_inds = np.argwhere(labels == cluster_ind)	        cluster_points = data[cluster_points_inds]	        if len(cluster_points) > 1:	            a_of_i_frac = 1 / (len(cluster_points) - 1)	            a_of_i_sum = 0	            for other_data_point in cluster_points:	                other_data_point.shape = (other_data_point.shape[1],)	                if not np.array_equal(data_point, other_data_point):	                    a_of_i_sum += (sum((i - j) ** 2 for i, j in zip(data_point, other_data_point))) ** 0.5	            a_of_i = a_of_i_frac * a_of_i_sum	            within_distances[result_ind] = a_of_i	        else:	            within_distances[result_ind] = 0	    return within_distances		save_history()
2024-11-17-16-39-34 106 30 # This cell is reserved for the unit tests. Do not consider this cell. 
2024-11-17-16-39-34 106 31 def nearest_cluster_distances(data: np.ndarray, labels: np.ndarray) -> np.ndarray:	    num_samples = data.shape[0]	    nearest_distances = np.zeros((num_samples,))	    for result_ind, (data_point, cluster_ind) in enumerate(zip(data, labels)):	        nearest_distance = 1e9	        num_clusters = max(labels)	        for other_cluster_ind in [ind for ind in range(num_clusters) if ind != cluster_ind]:	            other_cluster_points_inds = np.argwhere(labels == other_cluster_ind)	            other_cluster_points = data[other_cluster_points_inds]	            b_of_i_frac = 1 / len(other_cluster_points_inds)	            b_of_i_sum = 0	            for other_data_point in other_cluster_points:	                other_data_point.shape = (other_data_point.shape[1],)	                b_of_i_sum += (sum((i - j) ** 2 for i, j in zip(data_point, other_data_point))) ** 0.5	            b_of_i = b_of_i_frac * b_of_i_sum	            if b_of_i < nearest_distance:	                nearest_distance = b_of_i	        nearest_distances[result_ind] = nearest_distance	    return nearest_distances		save_history()
2024-11-17-16-39-34 106 32 # This cell is reserved for the unit tests. Do not consider this cell. 
