2024-11-08-13-20-59 87 1 from sklearn.decomposition import PCA	from sklearn.datasets import load_iris		def pca_with_svd(data: np.ndarray, n_components: int) -> np.ndarray:	    centred_data = data - np.mean(data, axis=0)	    u, s, vh = np.linalg.svd(centred_data)	    print(s)	    transformed_data = centred_data.dot(vh.T[:, :n_components])	    return transformed_data		df = load_iris()	X = df.data	pca = PCA(n_components=2)	X_proj = pca.fit_transform(X)	print(X_proj)	Y = df.data	print(pca_with_svd(Y, 2))	save_history()
2024-11-08-13-20-59 87 2 get_ipython().run_line_magic('matplotlib', 'inline')	import matplotlib.pyplot as plt	from typing import Tuple	import numpy as np	import scipy as sp	from submission_utils import save_history, check_and_prepare_for_submission	# import warnings filter	from warnings import simplefilter	# ignore all future warnings	simplefilter(action='ignore', category=FutureWarning)
2024-11-08-13-20-59 87 3 from sklearn.decomposition import PCA	from sklearn.datasets import load_iris		def pca_with_svd(data: np.ndarray, n_components: int) -> np.ndarray:	    centred_data = data - np.mean(data, axis=0)	    u, s, vh = np.linalg.svd(centred_data)	    print(s)	    transformed_data = centred_data.dot(vh.T[:, :n_components])	    return transformed_data		df = load_iris()	X = df.data	pca = PCA(n_components=2)	X_proj = pca.fit_transform(X)	print(X_proj)	Y = df.data	print(pca_with_svd(Y, 2))	save_history()
2024-11-08-13-20-59 87 4 from sklearn.decomposition import PCA	from sklearn.datasets import load_iris		def pca_with_svd(data: np.ndarray, n_components: int) -> np.ndarray:	    centred_data = data - np.mean(data, axis=0)	    u, s, vh = np.linalg.svd(centred_data)	    print(s)	    transformed_data = centred_data.dot(vh.T[:, :n_components])	    return transformed_data		df = load_iris()	# X = df.data	# pca = PCA(n_components=2)	# X_proj = pca.fit_transform(X)	# print(X_proj)	Y = df.data	pca_with_svd(Y, 2)	save_history()
2024-11-08-13-20-59 87 5 # from sklearn.decomposition import PCA	# from sklearn.datasets import load_iris		def pca_with_svd(data: np.ndarray, n_components: int) -> np.ndarray:	    centred_data = data - np.mean(data, axis=0)	    u, s, vh = np.linalg.svd(centred_data)	    transformed_data = centred_data.dot(vh.T[:, :n_components])	    return transformed_data		# df = load_iris()	# X = df.data	# pca = PCA(n_components=2)	# X_proj = pca.fit_transform(X)	# print(X_proj)	# Y = df.data	# print(pca_with_svd(Y, 2))	save_history()
2024-11-08-13-20-59 87 6 from sklearn.decomposition import PCA	from sklearn.datasets import load_iris		def pca_with_svd(data: np.ndarray, n_components: int) -> np.ndarray:	    centred_data = data - np.mean(data, axis=0)	    u, s, vh = np.linalg.svd(centred_data)	    print(np.diag(s))	    transformed_data = centred_data.dot(vh.T[:, :n_components])	    return transformed_data		df = load_iris()	# X = df.data	# pca = PCA(n_components=2)	# X_proj = pca.fit_transform(X)	# print(X_proj)	Y = df.data	pca_with_svd(Y, 2)	save_history()
2024-11-08-13-20-59 87 7 from sklearn.decomposition import PCA	from sklearn.datasets import load_iris		def pca_with_svd(data: np.ndarray, n_components: int) -> np.ndarray:	    centred_data = data - np.mean(data, axis=0)	    u, s, vh = np.linalg.svd(centred_data)	    print(s)	    transformed_data = centred_data.dot(vh.T[:, :n_components])	    return transformed_data		df = load_iris()	# X = df.data	# pca = PCA(n_components=2)	# X_proj = pca.fit_transform(X)	# print(X_proj)	Y = df.data	pca_with_svd(Y, 2)	save_history()
2024-11-08-13-20-59 87 8 # from sklearn.decomposition import PCA	# from sklearn.datasets import load_iris		def pca_with_svd(data: np.ndarray, n_components: int) -> np.ndarray:	    centred_data = data - np.mean(data, axis=0)	    u, s, vh = np.linalg.svd(centred_data)	    transformed_data = centred_data.dot(vh.T[:, :n_components])	    return transformed_data		# df = load_iris()	# X = df.data	# pca = PCA(n_components=2)	# X_proj = pca.fit_transform(X)	# print(X_proj)	# Y = df.data	# print(pca_with_svd(Y, 2))	save_history()
2024-11-08-13-20-59 87 9 from numpy import copy			def impute_missing_values(data: np.ndarray, rank: int) -> np.ndarray:	    no_nan_data = np.nan_to_num(data, nan=0)	    u, s, vh = np.linalg.svd(no_nan_data)	    s = np.diag(s)	    num_cols_u = u.shape[1]	    if num_cols_u > rank:	        u_trunc = u[:, :rank]	    else:	        u_trunc = u	    num_cols_vh = vh.shape[1]	    if num_cols_vh > rank:	        vh_trunc = vh[:, :rank]	    else:	        vh_trunc = vh	    num_sinuglar_values = s.shape[0]	    if num_sinuglar_values > rank:	        s_trunc = s[:rank, :]	    else:	        s_trunc = s	    trunc_svd_data = np.dot(np.dot(u_trunc, s_trunc), vh_trunc)	    nan_mask = np.isnan(data)	    nan_indices = np.where(nan_mask)	    imputed_data = copy.deepcopy(data)	    for indices in nan_indices:	        impute_value = trunc_svd_data[indices[0], indices[1]]	        imputed_data[indices[0], indices[1]] = impute_value	    return imputed_data		save_history()
2024-11-08-13-20-59 87 10 # Step 1: Create a 5-dimensional dataset with 3 clusters	num_clusters = 3	num_dimensions = 5	num_points = np.array([100, 100, 100])	cluster_std_devs = np.array([1.0, 1.0, 1.0])	center_std_dev = 3.0		data, labels = create_dataset(num_clusters, num_dimensions, num_points, cluster_std_devs, center_std_dev)		# Step 2: Plot the original data (2D projection using PCA)	print("Original Data (2D projection)")	plot_dataset(data, labels)		# Step 3: Introduce 10% missing values	nan_data = data.copy()	num_elements = nan_data.size	num_nan = int(0.1 * num_elements)  # 10% of the data		# Randomly choose 10% of indices to set as NaN	nan_indices = np.random.choice(num_elements, num_nan, replace=False)	nan_data.ravel()[nan_indices] = np.nan		# Step 4: Impute missing values using rank-4 SVD approximation	imputed_data = impute_missing_values(nan_data, rank=4)		# Step 5: Plot the imputed data (2D projection using PCA)	print("Imputed Data (2D projection)")	plot_dataset(imputed_data, labels)
2024-11-08-13-20-59 87 11 def create_dataset(num_clusters: int, 	                   num_dimensions: int, 	                   num_points: np.ndarray, 	                   cluster_std_devs: np.ndarray, 	                   center_std_dev: float) -> Tuple[np.ndarray, np.ndarray]:	    data = []	    labels = []	    origin = np.zeros((num_dimensions,))	    cluster_centres = np.random.normal(loc=origin, scale=center_std_dev, size=(num_clusters, num_dimensions))	    for i in range(num_clusters):	        cluster_points = np.random.normal(loc=cluster_centres[i], scale=cluster_std_devs[i], size=(num_points[i], num_dimensions))	        for point in cluster_points:	            data.append(point)	            labels.append(i)	    data = np.array(data)	    labels = np.array(labels)	    return (data, labels)	# data, labels = create_dataset(4, 5, np.array([4, 4, 4, 4, 4]), np.array([1, 3, 5, 7, 9]), 10)		save_history()
2024-11-08-13-20-59 87 12 import matplotlib.pyplot as plt	from sklearn.decomposition import PCA		def plot_dataset(data: np.ndarray, labels: np.ndarray) -> None:	    if (data.ndim == 1):	        return	    data_2d = PCA(n_components=2).fit_transform(data)	    plt.scatter(*data_2d.T, c=labels)	    plt.axis('equal')	    plt.xlabel('First PCA component')	    plt.ylabel('Second PCA component')	    plt.grid()	    plt.show()	    return		save_history()
2024-11-08-13-20-59 87 13 # Step 1: Create a 5-dimensional dataset with 3 clusters	num_clusters = 3	num_dimensions = 5	num_points = np.array([100, 100, 100])	cluster_std_devs = np.array([1.0, 1.0, 1.0])	center_std_dev = 3.0		data, labels = create_dataset(num_clusters, num_dimensions, num_points, cluster_std_devs, center_std_dev)		# Step 2: Plot the original data (2D projection using PCA)	print("Original Data (2D projection)")	plot_dataset(data, labels)		# Step 3: Introduce 10% missing values	nan_data = data.copy()	num_elements = nan_data.size	num_nan = int(0.1 * num_elements)  # 10% of the data		# Randomly choose 10% of indices to set as NaN	nan_indices = np.random.choice(num_elements, num_nan, replace=False)	nan_data.ravel()[nan_indices] = np.nan		# Step 4: Impute missing values using rank-4 SVD approximation	imputed_data = impute_missing_values(nan_data, rank=4)		# Step 5: Plot the imputed data (2D projection using PCA)	print("Imputed Data (2D projection)")	plot_dataset(imputed_data, labels)
2024-11-08-13-20-59 87 14 def impute_missing_values(data: np.ndarray, rank: int) -> np.ndarray:	    no_nan_data = np.nan_to_num(data, nan=0)	    u, s, vh = np.linalg.svd(no_nan_data)	    s = np.diag(s)	    num_cols_u = u.shape[1]	    if num_cols_u > rank:	        u_trunc = u[:, :rank]	    else:	        u_trunc = u	    num_cols_vh = vh.shape[1]	    if num_cols_vh > rank:	        vh_trunc = vh[:, :rank]	    else:	        vh_trunc = vh	    num_sinuglar_values = s.shape[0]	    if num_sinuglar_values > rank:	        s_trunc = s[:rank, :]	    else:	        s_trunc = s	    trunc_svd_data = np.dot(np.dot(u_trunc, s_trunc), vh_trunc)	    nan_mask = np.isnan(data)	    nan_indices = np.where(nan_mask)	    imputed_data = data.copy()	    for indices in nan_indices:	        impute_value = trunc_svd_data[indices[0], indices[1]]	        imputed_data[indices[0], indices[1]] = impute_value	    return imputed_data		save_history()
2024-11-08-13-20-59 87 15 # Step 1: Create a 5-dimensional dataset with 3 clusters	num_clusters = 3	num_dimensions = 5	num_points = np.array([100, 100, 100])	cluster_std_devs = np.array([1.0, 1.0, 1.0])	center_std_dev = 3.0		data, labels = create_dataset(num_clusters, num_dimensions, num_points, cluster_std_devs, center_std_dev)		# Step 2: Plot the original data (2D projection using PCA)	print("Original Data (2D projection)")	plot_dataset(data, labels)		# Step 3: Introduce 10% missing values	nan_data = data.copy()	num_elements = nan_data.size	num_nan = int(0.1 * num_elements)  # 10% of the data		# Randomly choose 10% of indices to set as NaN	nan_indices = np.random.choice(num_elements, num_nan, replace=False)	nan_data.ravel()[nan_indices] = np.nan		# Step 4: Impute missing values using rank-4 SVD approximation	imputed_data = impute_missing_values(nan_data, rank=4)		# Step 5: Plot the imputed data (2D projection using PCA)	print("Imputed Data (2D projection)")	plot_dataset(imputed_data, labels)
2024-11-08-13-20-59 87 16 def impute_missing_values(data: np.ndarray, rank: int) -> np.ndarray:	    no_nan_data = np.nan_to_num(data, nan=0)	    u, s, vh = np.linalg.svd(no_nan_data)	    s = np.diag(s)	    num_cols_u = u.shape[1]	    if num_cols_u > rank:	        u_trunc = u[:, :rank]	    else:	        u_trunc = u	    num_cols_vh = vh.shape[1]	    if num_cols_vh > rank:	        vh_trunc = vh[:, :rank]	    else:	        vh_trunc = vh	    num_sinuglar_values = s.shape[0]	    if num_sinuglar_values > rank:	        s_trunc = s[:rank, :]	    else:	        s_trunc = s	    trunc_svd_data = np.dot(np.dot(u_trunc, s_trunc), vh_trunc)	    nan_mask = np.isnan(data)	    nan_indices = np.where(nan_mask)	    imputed_data = data.copy()	    for indices in nan_indices:	        print((indices[0], indices[1]))	        impute_value = trunc_svd_data[indices[0], indices[1]]	        imputed_data[indices[0], indices[1]] = impute_value	    return imputed_data		save_history()
2024-11-08-13-20-59 87 17 # Step 1: Create a 5-dimensional dataset with 3 clusters	num_clusters = 3	num_dimensions = 5	num_points = np.array([100, 100, 100])	cluster_std_devs = np.array([1.0, 1.0, 1.0])	center_std_dev = 3.0		data, labels = create_dataset(num_clusters, num_dimensions, num_points, cluster_std_devs, center_std_dev)		# Step 2: Plot the original data (2D projection using PCA)	print("Original Data (2D projection)")	plot_dataset(data, labels)		# Step 3: Introduce 10% missing values	nan_data = data.copy()	num_elements = nan_data.size	num_nan = int(0.1 * num_elements)  # 10% of the data		# Randomly choose 10% of indices to set as NaN	nan_indices = np.random.choice(num_elements, num_nan, replace=False)	nan_data.ravel()[nan_indices] = np.nan		# Step 4: Impute missing values using rank-4 SVD approximation	imputed_data = impute_missing_values(nan_data, rank=4)		# Step 5: Plot the imputed data (2D projection using PCA)	print("Imputed Data (2D projection)")	plot_dataset(imputed_data, labels)
